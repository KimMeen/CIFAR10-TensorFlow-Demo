{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silverpond Internship Test\n",
    "+ Playing with convolutions: A notebook that looks at convolutions, purely independently of deep learning, and tests a few different varieties on images.\n",
    "+ **Ming Jin** >>> <mingj2@student.unimelb.edu.au>\n",
    "\n",
    "#### Step2-Prediction.ipynb\n",
    "This is the main gate for predicting the class of a signle image by using the model trained in step 1.\n",
    "\n",
    "#### Important Notices:\n",
    "+ This simplified version is based on my previous works, find out more via [this link](https://github.com/KimMeen/CIFAR10-Tensorflow-Single-Image-Test)\n",
    "+ This file need you to assign a test picture in these classes: airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks.\n",
    "+ Please double check the model you restored is the original one that you cloned from my repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimmeen/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "#import cv2\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cell 2:**\n",
    "+ **Please assign a picture(like the pictures in ./test_images folder) to test the model.**\n",
    "+ **Please assign the correct lable before you do the prediction(in order to compare the result in the end).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./test_images/jet2.jpg\"  # assign the test picture here\n",
    "input_number =  0                      # assign the test picture label here (0 - 9)\n",
    "image_size = 24                        # this is the input shape in CNN(after image cutting step)\n",
    "labels = ['plane','automobile','bird','cat','elk','dog','frog','horse','ship','truck',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cell 3:**\n",
    "+ Define the same preprocessing(parts of them) as in the training step\n",
    "+ Define the helper funtions that used in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _image_test_crop(images, crop_shape=(24,24,3)):\n",
    "        # image cutting\n",
    "        new_images = numpy.empty((images.shape[0],24,24,3))\n",
    "        for i in range(images.shape[0]):\n",
    "            old_image = images[i,:,:,:]\n",
    "            left = int((old_image.shape[0] - crop_shape[0])/2)\n",
    "            top = int((old_image.shape[1] - crop_shape[1])/2)\n",
    "            new_image = old_image[left:left+crop_shape[0],top:top+crop_shape[1], :]\n",
    "            new_images[i,:,:,:] = new_image\n",
    "            \n",
    "        return new_images\n",
    "\n",
    "def _image_whitening(images):\n",
    "        # image whiting\n",
    "        for i in range(images.shape[0]):\n",
    "            old_image = images[i,:,:,:]\n",
    "            new_image = (old_image - numpy.mean(old_image)) / numpy.std(old_image)\n",
    "            images[i,:,:,:] = new_image\n",
    "        \n",
    "        return images\n",
    "\n",
    "def conv_weight_variable(kernal_shape,input_shape):\n",
    "    initial = tf.truncated_normal(kernal_shape, stddev=numpy.sqrt(2.0 / (input_shape[0] * input_shape[1] * input_shape[2])))\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def fc_weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=numpy.sqrt(2.0 / shape[0]))\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def conv_batch_normal(x,b,n_filter,is_train=-1):\n",
    "    epsilon = 1e-5\n",
    "    gamma = tf.Variable(initial_value=tf.constant(1.0, shape=[n_filter]),trainable=False)\n",
    "    batch_mean, batch_var = tf.nn.moments(x, axes=[0, 1, 2], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "  \n",
    "    def mean_var_with_update():      \n",
    "        ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "    mean, variance = tf.cond(tf.greater(is_train,0), mean_var_with_update, lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "\n",
    "    return tf.nn.batch_normalization(x, mean, variance, b, gamma, epsilon)\n",
    "\n",
    "def fc_batch_normal(x,b,hidden_dim,is_train=-1):\n",
    "    epsilon = 1e-5\n",
    "    gamma = tf.Variable(initial_value=tf.constant(1.0, shape=[hidden_dim]),trainable=False)\n",
    "    batch_mean, batch_var = tf.nn.moments(x, axes=[0], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "  \n",
    "    def mean_var_with_update():      \n",
    "        ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "    mean, variance = tf.cond(tf.greater(is_train,0), mean_var_with_update, lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "\n",
    "    return tf.nn.batch_normalization(x, mean, variance, b, gamma, epsilon)  \n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cell 4:**\n",
    "+ Define the CNN used in prediction(same as in the training step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, image_size, image_size, 3])\n",
    "x_image = tf.reshape(xs, [-1, 24, 24, 3])\n",
    "\n",
    "## conv1 layer ##\n",
    "W_conv1 = conv_weight_variable([3,3,3,64],[image_size,image_size,3]) \n",
    "b_conv1 = bias_variable([64])\n",
    "h_conv1 = tf.nn.relu(conv_batch_normal(conv2d(x_image, W_conv1),b_conv1,64)) \n",
    "h_pool1 = max_pool_2x2(h_conv1)                          \n",
    "norm1 = tf.nn.local_response_normalization(h_pool1, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "\n",
    "## conv2 layer ##\n",
    "W_conv2 = conv_weight_variable([3,3,64,128],[int(image_size/2),int(image_size/2),64]) \n",
    "b_conv2 = bias_variable([128])\n",
    "h_conv2 = tf.nn.relu(conv_batch_normal(conv2d(norm1, W_conv2),b_conv2,128))\n",
    "h_pool2 = max_pool_2x2(h_conv2)                          \n",
    "norm2 = tf.nn.local_response_normalization(h_pool2, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "\n",
    "## conv3 layer ##\n",
    "W_conv3 = conv_weight_variable([3,3,128,256],[int(image_size/4),int(image_size/4),128]) \n",
    "b_conv3 = bias_variable([256])\n",
    "h_conv3 = tf.nn.relu(conv_batch_normal(conv2d(norm2, W_conv3),b_conv3,256))\n",
    "h_pool3 = max_pool_2x2(h_conv3)                          \n",
    "norm3 = tf.nn.local_response_normalization(h_pool3, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "\n",
    "## fc1 layer ##\n",
    "W_fc1 = fc_weight_variable([int(image_size/8)*int(image_size/8)*256, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_norm3_flat = tf.reshape(norm3, [-1,int(image_size/8)*int(image_size/8)*256])\n",
    "intermediate_fc1 = fc_batch_normal(tf.matmul(h_norm3_flat, W_fc1),b_fc1,1024)\n",
    "h_fc1 = tf.nn.relu(intermediate_fc1)\n",
    "\n",
    "## fc2 layer ##\n",
    "W_fc2 = fc_weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "intermediate_fc2 = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "h_fc2 = intermediate_fc2\n",
    "\n",
    "## softmax logic layer ##\n",
    "prediction = tf.nn.softmax(h_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cell 5:**\n",
    "+ Load the picture and do the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_path)\n",
    "\n",
    "if (image.size != (32,32)):\n",
    "    image = image.resize((32,32),Image.ANTIALIAS)\n",
    "    image = image.filter(ImageFilter.DETAIL)\n",
    "\n",
    "#image.save('./test_images/cat3_0_0.jpg')\n",
    "image = numpy.reshape(image, [1, 32, 32, 3])\n",
    "image = numpy.multiply(image, 1.0 / 255.0)\n",
    "image = _image_test_crop(image)\n",
    "image = _image_whitening(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cell 6:**\n",
    "+ Define a session that used in prediction\n",
    "+ Compare the predicted resut with the real label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt\n",
      "\n",
      "Model has been restored.\n",
      "\n",
      "-> The input image is : ./test_images/jet2.jpg\n",
      "-> The input label is : plane\n",
      "-> The output(predicted) label is : plane\n",
      "\n",
      "The prediction is correct!\n",
      "The confidence rate is: [ 0.99964237]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "   saver = tf.train.Saver()\n",
    "   ckpt = tf.train.get_checkpoint_state('./model/')\n",
    "   saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "   print(\"\\nModel has been restored.\\n\")\n",
    "   \n",
    "   result = sess.run(prediction, feed_dict={xs:image})\n",
    "   \n",
    "   max_index = numpy.argmax(result)\n",
    "   print(\"-> The input image is :\", image_path)\n",
    "   print(\"-> The input label is :\", labels[input_number])\n",
    "   print(\"-> The output(predicted) label is :\", labels[max_index])\n",
    "   \n",
    "   if (labels[input_number] == labels[max_index]):\n",
    "       print(\"\\nThe prediction is correct!\")\n",
    "   else:\n",
    "       print(\"The prediction is wrong!\")       \n",
    "   \n",
    "   print(\"The confidence rate is:\",result[:,max_index])\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
